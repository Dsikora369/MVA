{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Practical session on Transfer Learning**\n",
        "This Pratical session proposes to study several techniques for improving challenging context, in which few data and resources are available."
      ],
      "metadata": {
        "id": "4jVkOWmgFT1p"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLKnIngy_2hg"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "**Context :**\n",
        "\n",
        "Assume we are in a context where few \"gold\" labeled data are available for training, say \n",
        "\n",
        "$$\\mathcal{X}_{\\text{train}} = \\{(x_n,y_n)\\}_{n\\leq N_{\\text{train}}}$$\n",
        "\n",
        "where $N_{\\text{train}}$ is small. \n",
        "\n",
        "A large test set $\\mathcal{X}_{\\text{test}}$ as well as a large amount of unlabeled data, $\\mathcal{X}$, is available. We also assume that we have a limited computational budget (e.g., no GPUs).\n",
        "\n",
        "**Instructions to follow :** \n",
        "\n",
        "For each question, write a commented *Code* or a complete answer as a *Markdown*. When the objective of a question is to report a CNN accuracy, please use the following format to report it, at the end of the question :\n",
        "\n",
        "| Model | Number of  epochs  | Train accuracy | Test accuracy |\n",
        "|------|------|------|------|\n",
        "|   XXX  | XXX | XXX | XXX |\n",
        "\n",
        "If applicable, please add the field corresponding to the  __Accuracy on Full Data__ as well as a link to the __Reference paper__ you used to report those numbers. (You do not need to train a CNN on the full CIFAR10 dataset!)\n",
        "\n",
        "In your final report, please *keep the logs of each training procedure* you used. We will only run this jupyter if we have some doubts on your implementation. \n",
        "\n",
        "The total file sizes should be reasonable (feasible with 2MB only!). You will be asked to hand in the notebook, together with any necessary files required to run it if any.\n",
        "\n",
        "You can use https://colab.research.google.com/ to run your experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmTCQPSh_2hg"
      },
      "source": [
        "## Training set creation\n",
        "__Question 1 (2 points) :__ Propose a dataloader to obtain a training loader that will only use the first 100 samples of the CIFAR-10 training set.\n",
        "\n",
        "Additional information :  \n",
        "\n",
        "*   CIFAR10 dataset : https://en.wikipedia.org/wiki/CIFAR-10\n",
        "*   You can directly use the dataloader framework from Pytorch.\n",
        "*   Alternatively you can modify the file : https://github.com/pytorch/vision/blob/master/torchvision/datasets/cifar.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uZkC5IxR_2hh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42327d36-cdcb-475e-cfe1-0807997a8993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "batch_size = 20\n",
        "cifar_set_train = torchvision.datasets.CIFAR10(root =\"\\content\", train=True,\n",
        "                                               download=True , transform=transforms.ToTensor())\n",
        "sampler_100 = torch.utils.data.Subset(cifar_set_train, list(np.arange(100))) \n",
        "X_train = torch.utils.data.DataLoader(sampler_100, batch_size=batch_size, shuffle=True)\n",
        "cifar_set_test = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                        download=True, transform=transforms.ToTensor())\n",
        "X_test = torch.utils.data.DataLoader(cifar_set_test, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUno1nmu_2hh"
      },
      "source": [
        "* This is our dataset $\\mathcal{X}_{\\text{train}}$, it will be used until the end of this project. \n",
        "\n",
        "* The remaining samples correspond to $\\mathcal{X}$. \n",
        "\n",
        "* The testing set $\\mathcal{X}_{\\text{test}}$ corresponds to the whole testing set of CIFAR-10."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vr0d4o5L_2hi"
      },
      "source": [
        "## Testing procedure\n",
        "__Question 2 (1.5 points):__ Explain why the evaluation of the training procedure is difficult. Propose several solutions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppiTrnpd_2hi"
      },
      "source": [
        "**Answer 2:** The main problem is the small size of the training set. We have only 100 samples, what is obviously not enough for training. Therefore, we could (and probably would) encounter next problems. First, we one obvious problem is overfitting. The dataset is too small, so any more or less advanced model will simply remember and show no generalization after training. We can tackle this problem with usage of data augmentation or just use semi-supervised techniques. Second, the dataset would be imbalanced, so we would have small amount of data for one class, so the model won't be able to learn properly for this class. Also, there could be a problem of omiting of some classes(the probability is small, but worth of mentioning). In order to fight this problem, we can resample this dataset again and again until we get evenly distributed class. Also, we can find right class weight and adjust loss function to this weights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEaIwILB_2hi"
      },
      "source": [
        "# The Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-PQZ2Vl_2hi"
      },
      "source": [
        "In this section, the goal is to train a CNN on $\\mathcal{X}_{\\text{train}}$ and compare its performance with reported numbers from the litterature. You will have to re-use and/or design a standard classification pipeline. You should optimize your pipeline to obtain the best performances (image size, data augmentation by flip, ...).\n",
        "\n",
        "The key ingredients for training a CNN are the batch size, as well as the learning rate scheduler (i.e. how to decrease the learning rate as a function of the number of epochs). A possible scheduler is to start the learning rate at 0.1 and decreasing it every 30 epochs by 10. In case of divergence, reduce the learning rate. A potential batch size could be 10, yet this can be cross-validated.\n",
        "\n",
        "You can get some baselines accuracies in this paper (obviously, it is a different context for those researchers who had access to GPUs!) : http://openaccess.thecvf.com/content_cvpr_2018/papers/Keshari_Learning_Structure_and_CVPR_2018_paper.pdf. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARHWPXrY_2hi"
      },
      "source": [
        "## ResNet architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voMbGoNw_2hj"
      },
      "source": [
        "__Question 3 (4 points) :__ Write a classification pipeline for $\\mathcal{X}_{\\text{train}}$, train from scratch and evaluate a *ResNet-18* architecture specific to CIFAR10 (details about the ImageNet model can be found here: https://arxiv.org/abs/1512.03385). Please report the accuracy obtained on the whole dataset as well as the reference paper/GitHub link.\n",
        "\n",
        "*Hint :* You can re-use the following code : https://github.com/kuangliu/pytorch-cifar. During a training of 10 epochs, a batch size of 10 and a learning rate of 0.01, one obtains 40% accuracy on $\\mathcal{X}_{\\text{train}}$ (\\~2 minutes) and 20% accuracy on $\\mathcal{X}_{\\text{test}}$ (\\~5 minutes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RVHhKmWN_2hj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f9f1d78-aa8f-4ff1-8d72-480bc0965efb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5, Loss: 2.307, Accuracy: 31.0 %\n",
            "Epoch: 10, Loss: 1.168, Accuracy: 60.0 %\n",
            "Test_loss: 3.492, Test_accuracy: 20.100 %\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = 'cuda' if use_cuda else 'cpu'\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "def train(model, num_epochs, optimizer, scheduler, criterion, train_loader, verbose=True, device=device):\n",
        "    model = model.to(device)\n",
        "    training_losses = []\n",
        "    training_accuracies = []\n",
        "    for epoch in range(1, num_epochs+1): \n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        epoch_samples = 0\n",
        "        epoch_correct = 0   \n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "            predicted_batch = output.argmax(dim=1)\n",
        "            epoch_samples += len(target) \n",
        "            epoch_correct += (predicted_batch == target).sum()\n",
        "        epoch_accuracy = 100 * (epoch_correct / epoch_samples)\n",
        "        training_accuracies.append(epoch_accuracy.item())\n",
        "        average_epoch_loss = epoch_loss / len(train_loader)\n",
        "        training_losses.append(average_epoch_loss)\n",
        "        if verbose :\n",
        "            if epoch % 5 == 0: \n",
        "                print('Epoch: {}, Loss: {:.3f}, Accuracy: {:.1f} %'.format(epoch, average_epoch_loss, epoch_accuracy))\n",
        "\n",
        "    return training_accuracies, training_losses\n",
        "def test(model, criterion, device, test_loader, verbose=True):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        total_samples = 0\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()\n",
        "            predicted = output.argmax(dim=1)\n",
        "            correct += predicted.eq(target).sum().item()\n",
        "            total_samples += len(target)\n",
        "        accuracy = 100 * correct / total_samples\n",
        "        loss = test_loss / len(test_loader)\n",
        "        if verbose:\n",
        "            print('Test_loss: {:.3f}, Test_accuracy: {:.3f} %'.format(loss, accuracy))\n",
        "    return accuracy\n",
        "\n",
        "epochs = 10\n",
        "resnet18 = ResNet18()\n",
        "optimizer = torch.optim.SGD(resnet18.parameters(), lr=3e-2, momentum=0.9)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.2)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "train_accuracy, train_loss = train(resnet18, epochs, optimizer, scheduler, criterion, X_train)\n",
        "test_accuracy = test(resnet18, criterion, device, X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C3mHqCk_2hj"
      },
      "source": [
        "# Transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Tn9pW14_2hj"
      },
      "source": [
        "We propose to use pre-trained models on a classification and generative task, in order to improve the results of our setting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8g_3ZDi_2hj"
      },
      "source": [
        "## ImageNet features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfYEhdFb_2hj"
      },
      "source": [
        "Now, we will use some pre-trained models on ImageNet and see how well they compare on CIFAR. A list is available on : https://pytorch.org/vision/stable/models.html.\n",
        "\n",
        "__Question 4 (3 points):__ Pick a model from the list above, adapt it for CIFAR10 and retrain its final layer (or a block of layers, depending on the resources to which you have access to). Report its accuracy."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import mobilenet_v3_small\n",
        "import torch.nn as nn\n",
        "model = mobilenet_v3_small(pretrained=True)\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(in_features=576, out_features=128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(in_features=128, out_features=num_classes),\n",
        ")\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.02, momentum=0.8)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.2)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "  \n",
        "train_accuracy, train_loss = train(model, epochs, optimizer, scheduler, criterion, X_train)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "child_nbrs = 0\n",
        "for child in model.children():\n",
        "    child_nbrs += 1\n",
        "child_counter = 0\n",
        "for child in model.children():\n",
        "    if child_counter < child_nbrs//2 :\n",
        "        child_counter += 1\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = False\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "train_accuracy, train_loss = train(model, epochs, optimizer, scheduler, criterion, X_train) \n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "train_accuracy, train_loss = train(model, epochs, optimizer, scheduler, criterion, X_train) \n",
        "test_accuracy = test(model, criterion, device, X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe5XatvJnZhv",
        "outputId": "a48f9513-c219-41f3-9b6d-953f679102bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n",
            "100%|██████████| 9.83M/9.83M [00:00<00:00, 57.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5, Loss: 1.799, Accuracy: 44.0 %\n",
            "Epoch: 10, Loss: 1.216, Accuracy: 61.0 %\n",
            "Epoch: 15, Loss: 0.846, Accuracy: 78.0 %\n",
            "Epoch: 20, Loss: 0.793, Accuracy: 76.0 %\n",
            "Epoch: 25, Loss: 0.693, Accuracy: 74.0 %\n",
            "Epoch: 30, Loss: 0.722, Accuracy: 78.0 %\n",
            "Epoch: 35, Loss: 0.552, Accuracy: 84.0 %\n",
            "Epoch: 40, Loss: 0.532, Accuracy: 81.0 %\n",
            "Epoch: 45, Loss: 0.409, Accuracy: 88.0 %\n",
            "Epoch: 50, Loss: 0.349, Accuracy: 92.0 %\n",
            "Epoch: 5, Loss: 0.636, Accuracy: 82.0 %\n",
            "Epoch: 10, Loss: 0.409, Accuracy: 86.0 %\n",
            "Epoch: 15, Loss: 0.337, Accuracy: 88.0 %\n",
            "Epoch: 20, Loss: 0.412, Accuracy: 87.0 %\n",
            "Epoch: 25, Loss: 0.490, Accuracy: 85.0 %\n",
            "Epoch: 30, Loss: 0.336, Accuracy: 88.0 %\n",
            "Epoch: 35, Loss: 0.478, Accuracy: 86.0 %\n",
            "Epoch: 40, Loss: 0.272, Accuracy: 93.0 %\n",
            "Epoch: 45, Loss: 0.188, Accuracy: 94.0 %\n",
            "Epoch: 50, Loss: 0.247, Accuracy: 93.0 %\n",
            "Epoch: 5, Loss: 2.049, Accuracy: 26.0 %\n",
            "Epoch: 10, Loss: 1.071, Accuracy: 69.0 %\n",
            "Epoch: 15, Loss: 0.554, Accuracy: 81.0 %\n",
            "Epoch: 20, Loss: 0.288, Accuracy: 90.0 %\n",
            "Epoch: 25, Loss: 0.194, Accuracy: 95.0 %\n",
            "Epoch: 30, Loss: 0.303, Accuracy: 91.0 %\n",
            "Epoch: 35, Loss: 0.165, Accuracy: 93.0 %\n",
            "Epoch: 40, Loss: 0.324, Accuracy: 87.0 %\n",
            "Epoch: 45, Loss: 0.086, Accuracy: 98.0 %\n",
            "Epoch: 50, Loss: 0.127, Accuracy: 96.0 %\n",
            "Test_loss: 4.798, Test_accuracy: 16.370 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import mobilenet_v3_large\n",
        "model = mobilenet_v3_large(pretrained=True)\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(in_features=960, out_features=128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(in_features=128, out_features=num_classes),\n",
        ")\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.02, momentum=0.8)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.2)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "  \n",
        "train_accuracy, train_loss = train(model, epochs, optimizer, scheduler, criterion, X_train)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "child_nbrs = 0\n",
        "for child in model.children():\n",
        "    child_nbrs += 1\n",
        "child_counter = 0\n",
        "for child in model.children():\n",
        "    if child_counter < child_nbrs//2 :\n",
        "        child_counter += 1\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = False\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "train_accuracy, train_loss = train(model, epochs, optimizer, scheduler, criterion, X_train) \n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "train_accuracy, train_loss = train(model, epochs, optimizer, scheduler, criterion, X_train) \n",
        "test_accuracy = test(model, criterion, device, X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzfGn6_iqO-X",
        "outputId": "90abdb64-22b0-4dba-fd58-f40cd895619e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_large-8738ca79.pth\n",
            "100%|██████████| 21.1M/21.1M [00:00<00:00, 46.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5, Loss: 1.475, Accuracy: 56.0 %\n",
            "Epoch: 10, Loss: 0.766, Accuracy: 75.0 %\n",
            "Epoch: 15, Loss: 0.542, Accuracy: 85.0 %\n",
            "Epoch: 20, Loss: 0.440, Accuracy: 88.0 %\n",
            "Epoch: 25, Loss: 0.426, Accuracy: 86.0 %\n",
            "Epoch: 30, Loss: 0.382, Accuracy: 88.0 %\n",
            "Epoch: 35, Loss: 0.282, Accuracy: 89.0 %\n",
            "Epoch: 40, Loss: 0.339, Accuracy: 92.0 %\n",
            "Epoch: 45, Loss: 0.293, Accuracy: 90.0 %\n",
            "Epoch: 50, Loss: 0.446, Accuracy: 85.0 %\n",
            "Epoch: 5, Loss: 0.159, Accuracy: 97.0 %\n",
            "Epoch: 10, Loss: 0.237, Accuracy: 93.0 %\n",
            "Epoch: 15, Loss: 0.150, Accuracy: 94.0 %\n",
            "Epoch: 20, Loss: 0.126, Accuracy: 97.0 %\n",
            "Epoch: 25, Loss: 0.168, Accuracy: 97.0 %\n",
            "Epoch: 30, Loss: 0.156, Accuracy: 94.0 %\n",
            "Epoch: 35, Loss: 0.290, Accuracy: 91.0 %\n",
            "Epoch: 40, Loss: 0.126, Accuracy: 97.0 %\n",
            "Epoch: 45, Loss: 0.220, Accuracy: 93.0 %\n",
            "Epoch: 50, Loss: 0.069, Accuracy: 99.0 %\n",
            "Epoch: 5, Loss: 1.777, Accuracy: 37.0 %\n",
            "Epoch: 10, Loss: 0.570, Accuracy: 84.0 %\n",
            "Epoch: 15, Loss: 0.609, Accuracy: 80.0 %\n",
            "Epoch: 20, Loss: 0.371, Accuracy: 90.0 %\n",
            "Epoch: 25, Loss: 0.276, Accuracy: 93.0 %\n",
            "Epoch: 30, Loss: 0.224, Accuracy: 93.0 %\n",
            "Epoch: 35, Loss: 0.101, Accuracy: 96.0 %\n",
            "Epoch: 40, Loss: 0.086, Accuracy: 97.0 %\n",
            "Epoch: 45, Loss: 0.155, Accuracy: 94.0 %\n",
            "Epoch: 50, Loss: 0.180, Accuracy: 94.0 %\n",
            "Test_loss: 5.747, Test_accuracy: 18.220 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvkuMzLs_2hk"
      },
      "source": [
        "# Incorporating *a priori*\n",
        "Geometrical *a priori* are appealing for image classification tasks. For now, we only consider linear transformations $\\mathcal{T}$ of the inputs $x:\\mathbb{S}^2\\rightarrow\\mathbb{R}$ where $\\mathbb{S}$ is the support of an image, meaning that :\n",
        "\n",
        "$$\\forall u\\in\\mathbb{S}^2,\\mathcal{T}(\\lambda x+\\mu y)(u)=\\lambda \\mathcal{T}(x)(u)+\\mu \\mathcal{T}(y)(u)\\,.$$\n",
        "\n",
        "For instance if an image had an infinite support, a translation $\\mathcal{T}_a$ by $a$ would lead to :\n",
        "\n",
        "$$\\forall u, \\mathcal{T}_a(x)(u)=x(u-a)\\,.$$\n",
        "\n",
        "Otherwise, one has to handle several boundary effects.\n",
        "\n",
        "__Question 5 (1.5 points) :__ Explain the issues when dealing with translations, rotations, scaling effects, color changes on $32\\times32$ images. Propose several ideas to tackle them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIaY60o1_2hk"
      },
      "source": [
        "**Answer 5:** There are several problems that can emerge when working with translations, rotations, scaling effects, and color changes on 32x32 images:\n",
        "When a picture is translated or turned, portions of it may shift out of frame or become distorted, resulting in information loss. This can make it more challenging for the model to identify the picture accurately. Scaling effects can cause images to look larger or smaller, making it challenging for a model to correctly recognize objects in the image. Changes in illumination or hue can alter the look of a picture, making it more difficult for a model to correctly recognize items.\n",
        "\n",
        "Here are some solutions to these problems. We can produce more training data and teach the model to be more resilient to differences by adding modifications to the training pictures such as translations, rotations, scaling, and color changes. This can help minimize the risk of overfitting and increase the accuracy of the model. We can minimize the effect of differences in lighting conditions and color shifts by normalizing the pixel values of the pictures. This can help to make the model more resistant to such changes. We can use pre-trained models to utilize information acquired on large datasets to enhance the performance of our model on smaller datasets with fewer training instances. This can aid the model's generalization to new variants of the input pictures.  We can help the model learn to recognize things at various sizes by training it on pictures at varied scales, making it more resilient to changes in scaling effects. We can enhance the resilience of the model and reduce the risk of overfitting by merging the forecasts of multiple models trained with various augmentations or initialization methods. This can help to improve the model's precision on test data with differences that were not seen during training.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ds6e6teG_2hk"
      },
      "source": [
        "## Data augmentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ek5wlOo_2hk"
      },
      "source": [
        "__Question 6 (3 points):__ Propose a set of geometric transformation beyond translation, and incorporate them in your training pipeline. Train the model of the __Question 3__ with them and report the accuracies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "FqCjrXGk_2hk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f93ad462-2528-47fb-9e1e-36f62ea16e75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch: 5, Loss: 1.973, Accuracy: 31.0 %\n",
            "Epoch: 10, Loss: 1.601, Accuracy: 47.0 %\n",
            "Epoch: 15, Loss: 1.137, Accuracy: 62.0 %\n",
            "Epoch: 20, Loss: 0.874, Accuracy: 69.0 %\n",
            "Epoch: 25, Loss: 0.718, Accuracy: 73.0 %\n",
            "Epoch: 30, Loss: 0.615, Accuracy: 81.0 %\n",
            "Epoch: 35, Loss: 0.688, Accuracy: 73.0 %\n",
            "Epoch: 40, Loss: 0.411, Accuracy: 85.0 %\n",
            "Epoch: 45, Loss: 0.326, Accuracy: 88.0 %\n",
            "Epoch: 50, Loss: 0.425, Accuracy: 85.0 %\n",
            "Test_loss: 6.464, Test_accuracy: 19.920 %\n"
          ]
        }
      ],
      "source": [
        "train_trans = transforms.Compose([\n",
        "                 transforms.RandomHorizontalFlip(),\n",
        "                 transforms.RandomCrop(size=[32,32], padding=3),\n",
        "                 transforms.RandomRotation(degrees=15),\n",
        "                 transforms.ColorJitter(hue=.1),\n",
        "                 transforms.ToTensor(),\n",
        "                 ])\n",
        "test_trans = transforms.Compose([\n",
        "                 transforms.ToTensor(),\n",
        "])\n",
        "cifar_set_train = torchvision.datasets.CIFAR10(root =\"\\content\", train=True,\n",
        "                                               download=True , transform=train_trans)\n",
        "sampler_100 = torch.utils.data.Subset(cifar_set_train, list(np.arange(100))) \n",
        "X_train2 = torch.utils.data.DataLoader(sampler_100, batch_size=batch_size, shuffle=True)\n",
        "cifar_set_test = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                        download=True, transform=transforms.ToTensor())\n",
        "X_test2 = torch.utils.data.DataLoader(cifar_set_test, batch_size=batch_size, shuffle=False)\n",
        "epochs = 50\n",
        "resnet18 = ResNet18()\n",
        "optimizer = torch.optim.SGD(resnet18.parameters(), lr=1e-2, momentum=0.9)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.2)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "train_accuracy, train_loss = train(resnet18, epochs, optimizer, scheduler, criterion, X_train2)\n",
        "test_accuracy = test(resnet18, criterion, device, X_test2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = mobilenet_v3_small(pretrained=True)\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(in_features=576, out_features=128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(in_features=128, out_features=num_classes),\n",
        ")\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.02, momentum=0.8)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.2)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "  \n",
        "train_accuracy, train_loss = train(model, epochs, optimizer, scheduler, criterion, X_train2)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "child_nbrs = 0\n",
        "for child in model.children():\n",
        "    child_nbrs += 1\n",
        "child_counter = 0\n",
        "for child in model.children():\n",
        "    if child_counter < child_nbrs//2 :\n",
        "        child_counter += 1\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = False\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "train_accuracy, train_loss = train(model, epochs, optimizer, scheduler, criterion, X_train2) \n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "train_accuracy, train_loss = train(model, epochs, optimizer, scheduler, criterion, X_train2) \n",
        "test_accuracy = test(model, criterion, device, X_test2)"
      ],
      "metadata": {
        "id": "-mn8miGpKX3R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1d16a88-d88d-4003-eab0-16ea191e216a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5, Loss: 2.102, Accuracy: 26.0 %\n",
            "Epoch: 10, Loss: 2.015, Accuracy: 26.0 %\n",
            "Epoch: 15, Loss: 1.984, Accuracy: 30.0 %\n",
            "Epoch: 20, Loss: 1.934, Accuracy: 35.0 %\n",
            "Epoch: 25, Loss: 1.846, Accuracy: 32.0 %\n",
            "Epoch: 30, Loss: 1.875, Accuracy: 30.0 %\n",
            "Epoch: 35, Loss: 1.770, Accuracy: 35.0 %\n",
            "Epoch: 40, Loss: 1.904, Accuracy: 38.0 %\n",
            "Epoch: 45, Loss: 1.794, Accuracy: 35.0 %\n",
            "Epoch: 50, Loss: 1.733, Accuracy: 36.0 %\n",
            "Epoch: 5, Loss: 1.775, Accuracy: 36.0 %\n",
            "Epoch: 10, Loss: 1.805, Accuracy: 38.0 %\n",
            "Epoch: 15, Loss: 1.845, Accuracy: 35.0 %\n",
            "Epoch: 20, Loss: 1.806, Accuracy: 28.0 %\n",
            "Epoch: 25, Loss: 1.932, Accuracy: 36.0 %\n",
            "Epoch: 30, Loss: 1.841, Accuracy: 28.0 %\n",
            "Epoch: 35, Loss: 1.899, Accuracy: 30.0 %\n",
            "Epoch: 40, Loss: 1.804, Accuracy: 34.0 %\n",
            "Epoch: 45, Loss: 1.716, Accuracy: 37.0 %\n",
            "Epoch: 50, Loss: 1.756, Accuracy: 39.0 %\n",
            "Epoch: 5, Loss: 2.003, Accuracy: 22.0 %\n",
            "Epoch: 10, Loss: 2.011, Accuracy: 28.0 %\n",
            "Epoch: 15, Loss: 1.717, Accuracy: 37.0 %\n",
            "Epoch: 20, Loss: 1.402, Accuracy: 53.0 %\n",
            "Epoch: 25, Loss: 1.464, Accuracy: 48.0 %\n",
            "Epoch: 30, Loss: 1.291, Accuracy: 51.0 %\n",
            "Epoch: 35, Loss: 1.103, Accuracy: 62.0 %\n",
            "Epoch: 40, Loss: 0.871, Accuracy: 77.0 %\n",
            "Epoch: 45, Loss: 0.978, Accuracy: 65.0 %\n",
            "Epoch: 50, Loss: 0.865, Accuracy: 73.0 %\n",
            "Test_loss: 3.575, Test_accuracy: 23.150 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import mobilenet_v3_large\n",
        "model = mobilenet_v3_large(pretrained=True)\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(in_features=960, out_features=128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(in_features=128, out_features=num_classes),\n",
        ")\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.02, momentum=0.8)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.2)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "  \n",
        "train_accuracy, train_loss = train(model, epochs, optimizer, scheduler, criterion, X_train2)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "child_nbrs = 0\n",
        "for child in model.children():\n",
        "    child_nbrs += 1\n",
        "child_counter = 0\n",
        "for child in model.children():\n",
        "    if child_counter < child_nbrs//2 :\n",
        "        child_counter += 1\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = False\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "train_accuracy, train_loss = train(model, epochs, optimizer, scheduler, criterion, X_train2) \n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "train_accuracy, train_loss = train(model, epochs, optimizer, scheduler, criterion, X_train2) \n",
        "test_accuracy = test(model, criterion, device, X_test2)\n"
      ],
      "metadata": {
        "id": "WRx2aFY9KdL-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a97fe763-7fc9-49d9-cbd2-ff5c066452c8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5, Loss: 2.024, Accuracy: 23.0 %\n",
            "Epoch: 10, Loss: 1.786, Accuracy: 38.0 %\n",
            "Epoch: 15, Loss: 1.788, Accuracy: 36.0 %\n",
            "Epoch: 20, Loss: 1.813, Accuracy: 33.0 %\n",
            "Epoch: 25, Loss: 1.534, Accuracy: 53.0 %\n",
            "Epoch: 30, Loss: 1.560, Accuracy: 47.0 %\n",
            "Epoch: 35, Loss: 1.562, Accuracy: 45.0 %\n",
            "Epoch: 40, Loss: 1.465, Accuracy: 52.0 %\n",
            "Epoch: 45, Loss: 1.532, Accuracy: 52.0 %\n",
            "Epoch: 50, Loss: 1.338, Accuracy: 52.0 %\n",
            "Epoch: 5, Loss: 1.350, Accuracy: 57.0 %\n",
            "Epoch: 10, Loss: 1.583, Accuracy: 41.0 %\n",
            "Epoch: 15, Loss: 1.551, Accuracy: 47.0 %\n",
            "Epoch: 20, Loss: 1.291, Accuracy: 58.0 %\n",
            "Epoch: 25, Loss: 1.468, Accuracy: 50.0 %\n",
            "Epoch: 30, Loss: 1.290, Accuracy: 57.0 %\n",
            "Epoch: 35, Loss: 1.484, Accuracy: 46.0 %\n",
            "Epoch: 40, Loss: 1.198, Accuracy: 64.0 %\n",
            "Epoch: 45, Loss: 1.365, Accuracy: 52.0 %\n",
            "Epoch: 50, Loss: 1.291, Accuracy: 56.0 %\n",
            "Epoch: 5, Loss: 2.159, Accuracy: 20.0 %\n",
            "Epoch: 10, Loss: 1.451, Accuracy: 47.0 %\n",
            "Epoch: 15, Loss: 1.176, Accuracy: 62.0 %\n",
            "Epoch: 20, Loss: 0.762, Accuracy: 77.0 %\n",
            "Epoch: 25, Loss: 0.889, Accuracy: 66.0 %\n",
            "Epoch: 30, Loss: 0.543, Accuracy: 81.0 %\n",
            "Epoch: 35, Loss: 0.346, Accuracy: 89.0 %\n",
            "Epoch: 40, Loss: 0.381, Accuracy: 87.0 %\n",
            "Epoch: 45, Loss: 0.447, Accuracy: 84.0 %\n",
            "Epoch: 50, Loss: 0.202, Accuracy: 92.0 %\n",
            "Test_loss: 3.892, Test_accuracy: 26.370 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRUA5I8N_2hk"
      },
      "source": [
        "# Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmyiWAPJ_2hl"
      },
      "source": [
        "__Question 7 (5 points) :__ Write a short report explaining the pros and the cons of each method that you implemented. 25% of the grade of this project will correspond to this question, thus, it should be done carefully. In particular, please add a plot that will summarize all your numerical results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ-v4Nev_2hl"
      },
      "source": [
        "In this part of our project, we aimed to improve the accuracy of our image classification models by augmenting our 100-sample dataset with a set of geometric transformations. By randomly augmenting our images using these transformations, we hoped to ensure that the models would encounter different samples for every iteration, thus enhancing their ability to generalize and make accurate predictions on unseen data.\n",
        "\n",
        "To achieve this, we incorporated a pipeline of transformations using the torchvision.transforms.Compose() method. Specifically, we applied the following transformations: horizontally flip the given image randomly, randomly crop the input image, random rotation and randomly change the hue of an image.\n",
        "\n",
        "By applying this pipeline of data augmentation, we were able to improve the accuracy of some models we tried by up to 3.4%. In particular, we weren't able to improve the accuracy of the ResNet-18 model on the test set, we got from 20.10% to 19.92%. The best accuracy we obtained was 26.37% with the Pretrained MobileNetV3 model.\n",
        "\n",
        "Below, we report the accuracies of all the models we tried with and without data augmentation:\n",
        "\n",
        "| Model                | Accuracy with data augmentation | Accuracy without data augmentation |\n",
        "|----------------------|---------------------------------|------------------------------------|\n",
        "| ResNet-18            | 19.92%                          | 20.10%                             |\n",
        "| MobileNetV3Small            | 23.24%                          | 16.37%                             |\n",
        "| MobileNetV3Large | 26.37%                          | 18.22%                             |\n",
        "\n",
        "\n",
        "\n",
        "As the table shows, data augmentation consistently led to improved accuracy across most of the models we tried. We conclude that incorporating a pipeline of geometric transformations can be an effective way to enhance the performance of image classification models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAGp7ddN_2hl"
      },
      "source": [
        "# Weak supervision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHQRLbC3_2hl"
      },
      "source": [
        "__Bonus \\[open\\] question (up to 3 points) :__ Pick a weakly supervised method that will potentially use $\\mathcal{X}\\cup\\mathcal{X}_{\\text{train}}$ to train a representation (a subset of $\\mathcal{X}$ is also fine). Evaluate it and report the accuracies. You should be careful in the choice of your method, in order to avoid heavy computational effort."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbjhfIvN_2hl"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}